{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPSTONE PROJECT - PART 3\n",
    "__Michael Gat__  \n",
    "__General Assembly Santa Monica, Data Science Immersive, Summer 2016__\n",
    "\n",
    "In this notebook, we'll build upon the model, testing for different numbers of features selected by the Chi2 algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES ############################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ IN DATA\n",
    "We have a clean dataset from __Part 1__. We'll import that, then select only the columns we want to deal with at this time. This code is similar to __Part_2__, please review that notebook for additional details/comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetic_data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_model_1 = df.ix[:,0:15]\n",
    "df_model_1 = df_model_1.join(df.ix[:,['change', 'diabetesMed', 'age_group', 'readmit']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race                        int64\n",
       "gender                      int64\n",
       "admission_type_id           int64\n",
       "discharge_disposition_id    int64\n",
       "admission_source_id         int64\n",
       "time_in_hospital            int64\n",
       "num_lab_procedures          int64\n",
       "num_procedures              int64\n",
       "num_medications             int64\n",
       "number_outpatient           int64\n",
       "number_emergency            int64\n",
       "number_inpatient            int64\n",
       "number_diagnoses            int64\n",
       "max_glu_serum               int64\n",
       "A1Cresult                   int64\n",
       "change                      int64\n",
       "diabetesMed                 int64\n",
       "age_group                   int64\n",
       "readmit                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILD MORE SOPHISTICATED FEATURE SELECTION\n",
    "Still working with the recommended Chi2, test for different numbers of features, using code adapted from __Part2__.\n",
    "Key results in Capstone_Results.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECTED FEATURES:3\n",
      "discharge_disposition_id\n",
      "number_emergency\n",
      "number_inpatient\n",
      "[  1.73968535e-01   4.19195112e-01   9.42000153e+00   4.66594545e+02\n",
      "   2.66501730e+00   9.10867309e+01   5.19059937e+01   2.38182811e+01\n",
      "   1.64531678e+02   5.12599264e+01   4.35274663e+02   2.35338511e+03\n",
      "   5.32879553e+01   8.48713414e-01   5.50590197e+00   5.84219056e+00\n",
      "   2.34749296e+00]\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "0.887323943662\n",
      "[[67604   187]\n",
      " [ 8413   121]]\n",
      "AUC Metrics:\n",
      "0.505710050767\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features=1, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.887730101539\n",
      "[[67644   147]\n",
      " [ 8422   112]]\n",
      "AUC Metrics:\n",
      "0.505477772626\n",
      "\n",
      "GaussianNB()\n",
      "0.864919751065\n",
      "[[64997  2794]\n",
      " [ 7516  1018]]\n",
      "AUC Metrics:\n",
      "0.539036322563\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.887730101539\n",
      "[[67597   194]\n",
      " [ 8375   159]]\n",
      "AUC Metrics:\n",
      "0.507884810058\n",
      "\n",
      "SELECTED FEATURES:4\n",
      "discharge_disposition_id\n",
      "num_medications\n",
      "number_emergency\n",
      "number_inpatient\n",
      "[  1.73968535e-01   4.19195112e-01   9.42000153e+00   4.66594545e+02\n",
      "   2.66501730e+00   9.10867309e+01   5.19059937e+01   2.38182811e+01\n",
      "   1.64531678e+02   5.12599264e+01   4.35274663e+02   2.35338511e+03\n",
      "   5.32879553e+01   8.48713414e-01   5.50590197e+00   5.84219056e+00\n",
      "   2.34749296e+00]\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "0.886485424173\n",
      "[[67469   322]\n",
      " [ 8342   192]]\n",
      "AUC Metrics:\n",
      "0.508874174636\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features=1, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.887782509008\n",
      "[[67690   101]\n",
      " [ 8464    70]]\n",
      "AUC Metrics:\n",
      "0.503356305447\n",
      "\n",
      "GaussianNB()\n",
      "0.864697019325\n",
      "[[64965  2826]\n",
      " [ 7501  1033]]\n",
      "AUC Metrics:\n",
      "0.539679140623\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.887821814609\n",
      "[[67600   191]\n",
      " [ 8371   163]]\n",
      "AUC Metrics:\n",
      "0.50814129358\n",
      "\n",
      "SELECTED FEATURES:5\n",
      "discharge_disposition_id\n",
      "time_in_hospital\n",
      "num_medications\n",
      "number_emergency\n",
      "number_inpatient\n",
      "[  1.73968535e-01   4.19195112e-01   9.42000153e+00   4.66594545e+02\n",
      "   2.66501730e+00   9.10867309e+01   5.19059937e+01   2.38182811e+01\n",
      "   1.64531678e+02   5.12599264e+01   4.35274663e+02   2.35338511e+03\n",
      "   5.32879553e+01   8.48713414e-01   5.50590197e+00   5.84219056e+00\n",
      "   2.34749296e+00]\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "0.886564035375\n",
      "[[67465   326]\n",
      " [ 8332   202]]\n",
      "AUC Metrics:\n",
      "0.509430563921\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features=1, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.888005240747\n",
      "[[67763    28]\n",
      " [ 8520    14]]\n",
      "AUC Metrics:\n",
      "0.500613731329\n",
      "\n",
      "GaussianNB()\n",
      "0.864225352113\n",
      "[[64915  2876]\n",
      " [ 7487  1047]]\n",
      "AUC Metrics:\n",
      "0.540130608525\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.887664592204\n",
      "[[67594   197]\n",
      " [ 8377   157]]\n",
      "AUC Metrics:\n",
      "0.507745504882\n",
      "\n",
      "SELECTED FEATURES:6\n",
      "discharge_disposition_id\n",
      "time_in_hospital\n",
      "num_medications\n",
      "number_emergency\n",
      "number_inpatient\n",
      "number_diagnoses\n",
      "[  1.73968535e-01   4.19195112e-01   9.42000153e+00   4.66594545e+02\n",
      "   2.66501730e+00   9.10867309e+01   5.19059937e+01   2.38182811e+01\n",
      "   1.64531678e+02   5.12599264e+01   4.35274663e+02   2.35338511e+03\n",
      "   5.32879553e+01   8.48713414e-01   5.50590197e+00   5.84219056e+00\n",
      "   2.34749296e+00]\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "0.886197183099\n",
      "[[67447   344]\n",
      " [ 8342   192]]\n",
      "AUC Metrics:\n",
      "0.508711911208\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features=1, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.888096953816\n",
      "[[67767    24]\n",
      " [ 8517    17]]\n",
      "AUC Metrics:\n",
      "0.500819001288\n",
      "\n",
      "GaussianNB()\n",
      "0.864028824107\n",
      "[[64901  2890]\n",
      " [ 7488  1046]]\n",
      "AUC Metrics:\n",
      "0.539968760807\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.887703897805\n",
      "[[67601   190]\n",
      " [ 8381   153]]\n",
      "AUC Metrics:\n",
      "0.507562777463\n",
      "\n",
      "SELECTED FEATURES:7\n",
      "discharge_disposition_id\n",
      "time_in_hospital\n",
      "num_lab_procedures\n",
      "num_medications\n",
      "number_emergency\n",
      "number_inpatient\n",
      "number_diagnoses\n",
      "[  1.73968535e-01   4.19195112e-01   9.42000153e+00   4.66594545e+02\n",
      "   2.66501730e+00   9.10867309e+01   5.19059937e+01   2.38182811e+01\n",
      "   1.64531678e+02   5.12599264e+01   4.35274663e+02   2.35338511e+03\n",
      "   5.32879553e+01   8.48713414e-01   5.50590197e+00   5.84219056e+00\n",
      "   2.34749296e+00]\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "0.886144775631\n",
      "[[67468   323]\n",
      " [ 8367   167]]\n",
      "AUC Metrics:\n",
      "0.507402069707\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features=1, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.888096953816\n",
      "[[67774    17]\n",
      " [ 8524    10]]\n",
      "AUC Metrics:\n",
      "0.500460506352\n",
      "\n",
      "GaussianNB()\n",
      "0.86388470357\n",
      "[[64891  2900]\n",
      " [ 7489  1045]]\n",
      "AUC Metrics:\n",
      "0.539836415531\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.887677694071\n",
      "[[67599   192]\n",
      " [ 8381   153]]\n",
      "AUC Metrics:\n",
      "0.507548026243\n",
      "\n",
      "SELECTED FEATURES:8\n",
      "discharge_disposition_id\n",
      "time_in_hospital\n",
      "num_lab_procedures\n",
      "num_medications\n",
      "number_outpatient\n",
      "number_emergency\n",
      "number_inpatient\n",
      "number_diagnoses\n",
      "[  1.73968535e-01   4.19195112e-01   9.42000153e+00   4.66594545e+02\n",
      "   2.66501730e+00   9.10867309e+01   5.19059937e+01   2.38182811e+01\n",
      "   1.64531678e+02   5.12599264e+01   4.35274663e+02   2.35338511e+03\n",
      "   5.32879553e+01   8.48713414e-01   5.50590197e+00   5.84219056e+00\n",
      "   2.34749296e+00]\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "0.885961349492\n",
      "[[67433   358]\n",
      " [ 8346   188]]\n",
      "AUC Metrics:\n",
      "0.508374295973\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features=1, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.888175565018\n",
      "[[67788     3]\n",
      " [ 8532     2]]\n",
      "AUC Metrics:\n",
      "0.500095051514\n",
      "\n",
      "GaussianNB()\n",
      "0.862731739273\n",
      "[[64789  3002]\n",
      " [ 7475  1059]]\n",
      "AUC Metrics:\n",
      "0.539904351695\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.887690795938\n",
      "[[67599   192]\n",
      " [ 8380   154]]\n",
      "AUC Metrics:\n",
      "0.507606615415\n",
      "\n",
      "SELECTED FEATURES:9\n",
      "discharge_disposition_id\n",
      "time_in_hospital\n",
      "num_lab_procedures\n",
      "num_procedures\n",
      "num_medications\n",
      "number_outpatient\n",
      "number_emergency\n",
      "number_inpatient\n",
      "number_diagnoses\n",
      "[  1.73968535e-01   4.19195112e-01   9.42000153e+00   4.66594545e+02\n",
      "   2.66501730e+00   9.10867309e+01   5.19059937e+01   2.38182811e+01\n",
      "   1.64531678e+02   5.12599264e+01   4.35274663e+02   2.35338511e+03\n",
      "   5.32879553e+01   8.48713414e-01   5.50590197e+00   5.84219056e+00\n",
      "   2.34749296e+00]\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "0.885738617753\n",
      "[[67416   375]\n",
      " [ 8346   188]]\n",
      "AUC Metrics:\n",
      "0.508248910597\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features=1, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.888162463151\n",
      "[[67786     5]\n",
      " [ 8531     3]]\n",
      "AUC Metrics:\n",
      "0.500138889467\n",
      "\n",
      "GaussianNB()\n",
      "0.862404192597\n",
      "[[64769  3022]\n",
      " [ 7480  1054]]\n",
      "AUC Metrics:\n",
      "0.539463893625\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.887743203406\n",
      "[[67601   190]\n",
      " [ 8378   156]]\n",
      "AUC Metrics:\n",
      "0.507738544981\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_model_1.ix[:,0:17]\n",
    "y = df_model_1.ix[:,18]\n",
    "#X_norm = StandardScaler().fit_transform(X)\n",
    "\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.75)\n",
    "\n",
    "classifiers = [DecisionTreeClassifier(max_depth=7), \\\n",
    "RandomForestClassifier(max_depth=7, n_estimators=10, max_features=1), \\\n",
    "GaussianNB(), LogisticRegression()]\n",
    "\n",
    "for numtest in range (3,10):\n",
    "    ch2 = SelectKBest(chi2, k=numtest)\n",
    "    X_train_fit = ch2.fit_transform(X_train, y_train)\n",
    "    print 'SELECTED FEATURES:' + str(numtest)\n",
    "    col_indices = ch2.get_support(indices=True)\n",
    "    for i in col_indices:\n",
    "        print X_train.columns.values[i]\n",
    "    print ch2.scores_\n",
    "    print\n",
    "    X_test_xform = ch2.transform(X_test)\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        clf.fit(X_train_fit, y_train)\n",
    "        score = clf.score(X_test_xform, y_test)\n",
    "        y_pred = clf.predict(X_test_xform)\n",
    "        y_pred = clf.predict(X_test_xform)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "        print clf\n",
    "        print score\n",
    "        print cm\n",
    "        print \"AUC Metrics:\"\n",
    "        print auc(fpr, tpr)\n",
    "        print\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
