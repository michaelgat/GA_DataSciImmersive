{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary predictor with Logistic Regression.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use Logistic Regression.\n",
    "\n",
    "- Question: Why would we want this to be a classification problem?\n",
    "- Answer: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9732c901-ae26-4160-8376-42e22dd327df"
   },
   "source": [
    "#### Setup a request (using `requests`) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "e915023e-6b0d-4982-af2a-b1e0355f4927"
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "2efefc73-064a-482d-b3b5-ddf5508cb4ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mg/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4e8a74d207b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m        \u001b[1;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m        \u001b[0mINDEED_URL_UNIQUE\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mINDEED_URL\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m        \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINDEED_URL_UNIQUE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m        \u001b[0msoup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"html\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m        \u001b[0mresults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\" row result\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"row result\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mg/anaconda2/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mg/anaconda2/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mg/anaconda2/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    473\u001b[0m         }\n\u001b[0;32m    474\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mg/anaconda2/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mg/anaconda2/lib/python2.7/site-packages/requests/models.pyc\u001b[0m in \u001b[0;36mcontent\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 741\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mg/anaconda2/lib/python2.7/site-packages/requests/models.pyc\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    662\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stream'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mg/anaconda2/lib/python2.7/site-packages/requests/packages/urllib3/response.pyc\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \"\"\"\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mg/anaconda2/lib/python2.7/site-packages/requests/packages/urllib3/response.pyc\u001b[0m in \u001b[0;36mread_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mg/anaconda2/lib/python2.7/site-packages/requests/packages/urllib3/response.pyc\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb';'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mg/anaconda2/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m                     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rbufsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "###                                                                    ###    \n",
    "### Credit where it's due:                                             ###\n",
    "### Almost all this work was from Shahram. Running it took hours and I ###\n",
    "### am including it for reference. I will be referring to a dataset    ###\n",
    "### That I extracted going forward.                                    ###\n",
    "###                                                                    ### \n",
    "### DO NOT RUN! TAKES FOREVER! MAY GET KICKED OFF INDEED.COM!          ###  \n",
    "###                                                                    ### \n",
    "##########################################################################\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "INDEED_URL_1='http://www.indeed.com/jobs?q=Data+Scientist&l='\n",
    "INDEED_URL='http://www.indeed.com/jobs?q=Data+Scientist&start='\n",
    "project4=pd.DataFrame(columns=['title','company','location','salary','description'])\n",
    "for i in range (1,100):\n",
    "   if i==0:\n",
    "       print i\n",
    "       INDEED_URL=INDEED_URL_1\n",
    "       r=requests.get(INDEED_URL)\n",
    "       soup=BeautifulSoup(r.text,\"html\")\n",
    "       results=soup.findAll('div',{\"class\":\" row result\"})+soup.findAll('div',{\"class\":\"row result\"})\n",
    "       for result in results:\n",
    "           title=''\n",
    "           company=''\n",
    "           location=''\n",
    "           salary=''\n",
    "           description=''\n",
    "           try:\n",
    "               temp=result.select('h2.jobtitle')\n",
    "               title=temp[0].text.strip()\n",
    "           except:\n",
    "               pass\n",
    "           try:\n",
    "               temp=result.select('span.company')\n",
    "               company=temp[0].text.strip()\n",
    "           except:\n",
    "               pass\n",
    "           try:\n",
    "               temp=result.select('span.location')\n",
    "               location=temp[0].text.strip()\n",
    "           except:\n",
    "               pass\n",
    "           try:\n",
    "               temp=result.select('nobr')\n",
    "               salary=temp[0].text.strip()\n",
    "           except:\n",
    "               pass\n",
    "           try:\n",
    "               temp=result.select('span.summary')\n",
    "               description=temp[0].text.strip()\n",
    "           except:\n",
    "               pass\n",
    "           project4.loc[len(project4)]=[title,company,location,salary,description]            \n",
    "\n",
    "   else:\n",
    "#         if (i%100==0):\n",
    "       print i\n",
    "       INDEED_URL_UNIQUE=INDEED_URL+str(i*10)\n",
    "       r=requests.get(INDEED_URL_UNIQUE)\n",
    "       soup=BeautifulSoup(r.text,\"html\")\n",
    "       results=soup.findAll('div',{\"class\":\" row result\"})+soup.findAll('div',{\"class\":\"row result\"})\n",
    "       for result in results:\n",
    "           title=''\n",
    "           company=''\n",
    "           location=''\n",
    "           salary=''\n",
    "           description=''\n",
    "           try:\n",
    "               temp=result.select('h2.jobtitle')\n",
    "               title=temp[0].text.strip()\n",
    "           except:\n",
    "               pass\n",
    "           try:\n",
    "               temp=result.select('span.company')\n",
    "               company=temp[0].text.strip()\n",
    "           except:\n",
    "               pass\n",
    "           try:\n",
    "               temp=result.select('span.location')\n",
    "               location=temp[0].text.strip()\n",
    "           except:\n",
    "               pass\n",
    "           try:\n",
    "               temp=result.select('nobr')\n",
    "               salary=temp[0].text.strip()\n",
    "           except:\n",
    "               pass\n",
    "           try:\n",
    "               temp=result.select('span.summary')\n",
    "               description=temp[0].text.strip()\n",
    "           except:\n",
    "               pass\n",
    "           project4.loc[len(project4)]=[title,company,location,salary,description]   \n",
    "project4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist II - Charlotte, NC</td>\n",
       "      <td>Bank of America</td>\n",
       "      <td>Charlotte, NC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As well as deployment of advanced techniques (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Simple Finance</td>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Predictive analytics, experimental design, dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Collaborate with other research scientists and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Shuchi Rana Sandbox</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Experiment engineers will be expected to help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist, Google Analytics 360, Google T...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lead analytics aspects of client engagements i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0                  Data Scientist II - Charlotte, NC   \n",
       "1           1                                     Data Scientist   \n",
       "2           2                           Associate Data Scientist   \n",
       "3           3                                     Data Scientist   \n",
       "4           4  Data Scientist, Google Analytics 360, Google T...   \n",
       "\n",
       "               company           location salary  \\\n",
       "0      Bank of America      Charlotte, NC    NaN   \n",
       "1       Simple Finance       Portland, OR    NaN   \n",
       "2               PayPal       San Jose, CA    NaN   \n",
       "3  Shuchi Rana Sandbox     Menlo Park, CA    NaN   \n",
       "4               Google  Mountain View, CA    NaN   \n",
       "\n",
       "                                         description  \n",
       "0  As well as deployment of advanced techniques (...  \n",
       "1  Predictive analytics, experimental design, dat...  \n",
       "2  Collaborate with other research scientists and...  \n",
       "3  Experiment engineers will be expected to help ...  \n",
       "4  Lead analytics aspects of client engagements i...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################################################\n",
    "###                                                                    ###    \n",
    "### Read in file we already have of scraped info                       ###\n",
    "###                                                                    ### \n",
    "##########################################################################\n",
    "import pandas as pd\n",
    "\n",
    "project4 = pd.read_csv('../assets/indeed_scrape_proj4.csv')\n",
    "project4.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "2c6752c4-7704-4c94-8bc0-6f13d2d0d570"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "f1eddb90-4ba8-483c-a229-77e93aa53119"
   },
   "source": [
    "### Write 4 functions to extract each item: location, company, job, and salary.\n",
    "\n",
    "example: \n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "\n",
    "- Make sure these functions are robust and can handle cases where the data/field may not be available.\n",
    "- Test the functions on the results above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a1af53c9-9090-494f-b82e-cadb60a54909"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34070e89-9521-4b45-90c8-57a6599aac68"
   },
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results, the `l=New+York` and the `start=10`. The first controls the location of the results (so we can try a different city). The second controls where in the results to start and gives 10 results (thus, we can keep incrementing by 10 to go further in the list)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "e8beed7c-3e42-40c0-810f-5f67f8f885a0"
   },
   "source": [
    "#### Complete the following code to collect results from multiple cities and starting points. \n",
    "- Enter your city below to add it to the search\n",
    "- Remember to convert your salary to U.S. Dollars to match the other cities if the currency is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a9aa87ec-3575-4a01-a986-eb684f2c47d0"
   },
   "outputs": [],
   "source": [
    "YOUR_CITY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "04b0f9af-540e-402f-8292-81748707c676"
   },
   "outputs": [],
   "source": [
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 100\n",
    "\n",
    "results = []\n",
    "\n",
    "for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', YOUR_CITY]):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        # Grab the results from the request (as above)\n",
    "        # Append to the full set of results\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "20339c09-5032-4e27-91be-286e9b46cd13"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "6e259594-1c52-436b-ab9e-527e071941c1"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "1. Some of the salaries are not yearly but hourly, these will be useful to us for now\n",
    "2. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Filter out the salaries that are not yearly (filter those that refer to hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '$120,00'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-385e1c9918cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m10000000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m        \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNumber_Splitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m    \u001b[1;31m# Fix the Hourly (Single)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-385e1c9918cc>\u001b[0m in \u001b[0;36mNumber_Splitter\u001b[1;34m(number)\u001b[0m\n\u001b[0;32m      8\u001b[0m    \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m        \u001b[0mnumber_2\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mnumber_str\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m    \u001b[0mnum_out\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mnum_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '$120,00'"
     ]
    }
   ],
   "source": [
    "def Number_Splitter(number):\n",
    "   number_str=list(str(number))\n",
    "   number_1=''\n",
    "   number_2=''\n",
    "   i=len(number_str)/2\n",
    "   for j in range(0,i):\n",
    "       number_1+=number_str[j]\n",
    "   for j in range(i,len(number_str)):\n",
    "       number_2+=number_str[j]                \n",
    "   num_out=0.5*(int(number_1)+int(number_2))\n",
    "   return num_out\n",
    "\n",
    "X = project4['salary']\n",
    "\n",
    "for i in range(0,len(X)):\n",
    "   if X[i]>10000000:\n",
    "       X[i]=Number_Splitter(X[i])\n",
    "   # Fix the Hourly (Single)\n",
    "   if X[i]<300:\n",
    "       X[i]=2000*X[i]\n",
    "   # Fix the Month (Single)\n",
    "   if (X[i]<40000 and X[i]>1000):\n",
    "       X[i]=12*X[i]\n",
    "       \n",
    "\"\"\"\n",
    "temp_cat=[]      \n",
    "for i in range(0,len(X)):\n",
    "   t='nan'\n",
    "   if (X[i]<100000):\n",
    "       t=0\n",
    "   if (X[i]>=100000 and X[i]<150000): \n",
    "       t=1\n",
    "   if (X[i]>=150000): \n",
    "       t=2\n",
    "   temp_cat.append(t)\n",
    "       \n",
    "test['salary_cat'] = temp_cat\n",
    "\"\"\"\n",
    "\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7d4bc860-b214-4f75-9cd0-b234830b1ec2"
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "source": [
    "Unknown without knowing more about the data distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Logistic Regression model to predict High/Low salary using statsmodel. Start by ONLY using the location as a feature. Display the coefficients and write a short summary of what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' is in the title \n",
    "- or whether 'Manager' is in the title. \n",
    "- Then build a new Logistic Regression model with these features. Do they add any value? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "068dc1cf-7fd7-4f27-a1f1-7f0a5a221d29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>description</th>\n",
       "      <th>senior</th>\n",
       "      <th>manager</th>\n",
       "      <th>expert</th>\n",
       "      <th>machlearn</th>\n",
       "      <th>bigdata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist II - Charlotte, NC</td>\n",
       "      <td>Bank of America</td>\n",
       "      <td>Charlotte, NC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As well as deployment of advanced techniques (...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Simple Finance</td>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Predictive analytics, experimental design, dat...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Collaborate with other research scientists and...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Shuchi Rana Sandbox</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Experiment engineers will be expected to help ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist, Google Analytics 360, Google T...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lead analytics aspects of client engagements i...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>USA - Data Scientist</td>\n",
       "      <td>Appnomic Systems Pvt. Ltd</td>\n",
       "      <td>Sunnyvale, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Weâ€™re looking for a data scientist to help us ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Simplion Technologies Inc</td>\n",
       "      <td>Sunnyvale, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Experienced in developing machine learning mod...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Lawrence Livermore National Laboratory</td>\n",
       "      <td>Livermore, CA 94550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data intensive applications, text processing, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>SPIN Analytics and Strategy LLC</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communicate insights and recommend areas for f...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Uber</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technical understanding must go from the highe...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ford Motor Company</td>\n",
       "      <td>Dearborn, MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business users, existing data sources, databas...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HireStarter</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Programming and experience required in SQL, Or...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Intuit</td>\n",
       "      <td>Mountain View, CA 94039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deep mastery of machine learning - Candidate m...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>kWh Analytics</td>\n",
       "      <td>San Francisco, CA 94104 (Financial District area)</td>\n",
       "      <td>$120,000 a year</td>\n",
       "      <td>A track record of spotting relevant trends in ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kohl's Corporation</td>\n",
       "      <td>Milpitas, CA 95035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data scientists interpret and apply data in an...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Data Scientist / Applied Researcher</td>\n",
       "      <td>EBay</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We use state-of-the-art big data infrastructur...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>R Statistician/Data Scientist</td>\n",
       "      <td>Data Management Services, Inc.</td>\n",
       "      <td>Frederick, MD 21701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Management Services, Inc., is currently s...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Sr. Financial Analyst / Data Scientist</td>\n",
       "      <td>Tech Quarry LLC</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Financial Analyst / Data Scientist*. Experienc...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Algorithm and Data Scientist (Machine Learning)</td>\n",
       "      <td>OnboardIQ</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Come help us build a brand new data platform, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>Richmond, VA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assess data quality, prepare data for processi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Data Scientist- Digital Marketing</td>\n",
       "      <td>Agilent</td>\n",
       "      <td>Santa Clara, CA 95051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You will be responsible for end to end analyti...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AbilTo, Inc</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>With our Engagement team, you will build predi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DoubleDown Interactive</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As a Senior Data Warehouse Engineer, you will ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sekisui XenoTech, LLC</td>\n",
       "      <td>Kansas City, KS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Serves as Lead Scientist or Study Director. Th...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>eHire, LLC</td>\n",
       "      <td>Atlanta, GA 30326 (Buckhead area)</td>\n",
       "      <td>$150,000 a year</td>\n",
       "      <td>Strong background in applying statistical mach...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GoodDolphin Technologies</td>\n",
       "      <td>Sunnyvale, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Design, develop, and implement statistical and...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Zynga</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Probability, statistics, data mining, predicti...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>ANALYTICAL SCIENTIST I Nike</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Requires chemistry, mechanical, material scien...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Zillow</td>\n",
       "      <td>Seattle, WA 98101 (Downtown area)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In particular, this role will span the gamut, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>LumenData</td>\n",
       "      <td>Santa Clara, CA 95054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Classifying streaming machine data to enable p...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Data Scientist, Proactive Intelligence</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Santa Clara Valley, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Experience with machine learning or data minin...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Data Scientist - Maps</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Santa Clara Valley, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We are a cross functional group of statisticia...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>Big Data â€“ Machine Learning Expert / Principal...</td>\n",
       "      <td>Humana</td>\n",
       "      <td>Irving, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Big Data â€“ Machine Learning Expert / Principal...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HireStarter</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Programming and experience required in SQL, Or...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Uber</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technical understanding must go from the highe...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AbilTo, Inc</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>With our Engagement team, you will build predi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>Data Scientist - Social Media</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Sunnyvale, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bing is seeking experienced data scientists an...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Caerus Associates</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Caerus is seeking an experienced data scientis...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Associate Data Scientist I/II - Eden Prairie MN</td>\n",
       "      <td>Supervalu</td>\n",
       "      <td>Eden Prairie, MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Develops machine learning, data mining,. Visua...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>CGG</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Experience and/or education in at least one of...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>The World Bank</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DIME Analytics provides support to research te...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>EventBoard</td>\n",
       "      <td>Salt Lake City, UT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The RoleWeâ€™re growing fast and need a top notc...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>Data Analytics Scientist, Knowledge Informatics</td>\n",
       "      <td>Foundation Medicine, Inc.</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The analytics scientist will be responsible fo...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>Data Scientist 2</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>Broomfield, CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-2 years of data science or applied analytics...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MD Insider</td>\n",
       "      <td>Santa Monica, CA 90405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R, Python, Java, SQL. Reporting to the Directo...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AbilTo, Inc</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>With our Engagement team, you will build predi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DoubleDown Interactive</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As a Senior Data Warehouse Engineer, you will ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sekisui XenoTech, LLC</td>\n",
       "      <td>Kansas City, KS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Serves as Lead Scientist or Study Director. Th...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Sr. Data Engineer / Data Scientist</td>\n",
       "      <td>Nineteen Eleven Solutions(Implementing Partner)</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist has 3 components. Development o...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ektello</td>\n",
       "      <td>Farmington Hills, MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technical experience in Deep Learning (academi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                              title  \\\n",
       "0            0                  Data Scientist II - Charlotte, NC   \n",
       "1            1                                     Data Scientist   \n",
       "2            2                           Associate Data Scientist   \n",
       "3            3                                     Data Scientist   \n",
       "4            4  Data Scientist, Google Analytics 360, Google T...   \n",
       "5            5                               USA - Data Scientist   \n",
       "6            6                                     Data Scientist   \n",
       "7            7                                     Data Scientist   \n",
       "8            8                                     Data Scientist   \n",
       "9            9                                                NaN   \n",
       "10          10                                                NaN   \n",
       "11          11                                                NaN   \n",
       "12          12                                     Data Scientist   \n",
       "13          13                                     Data Scientist   \n",
       "14          14                                     Data Scientist   \n",
       "15          15                Data Scientist / Applied Researcher   \n",
       "16          16                      R Statistician/Data Scientist   \n",
       "17          17             Sr. Financial Analyst / Data Scientist   \n",
       "18          18    Algorithm and Data Scientist (Machine Learning)   \n",
       "19          19                                     Data Scientist   \n",
       "20          20                  Data Scientist- Digital Marketing   \n",
       "21          21                                                NaN   \n",
       "22          22                                                NaN   \n",
       "23          23                                                NaN   \n",
       "24          24                                  Sr Data Scientist   \n",
       "25          25                                     Data Scientist   \n",
       "26          26                                     Data Scientist   \n",
       "27          27                        ANALYTICAL SCIENTIST I Nike   \n",
       "28          28                                     Data Scientist   \n",
       "29          29                                     Data Scientist   \n",
       "30          30             Data Scientist, Proactive Intelligence   \n",
       "31          31                              Data Scientist - Maps   \n",
       "32          32  Big Data â€“ Machine Learning Expert / Principal...   \n",
       "33          33                                                NaN   \n",
       "34          34                                                NaN   \n",
       "35          35                                                NaN   \n",
       "36          36                      Data Scientist - Social Media   \n",
       "37          37                                     Data Scientist   \n",
       "38          38    Associate Data Scientist I/II - Eden Prairie MN   \n",
       "39          39                                     Data Scientist   \n",
       "40          40                                   Research Analyst   \n",
       "41          41                                     Data Scientist   \n",
       "42          42    Data Analytics Scientist, Knowledge Informatics   \n",
       "43          43                                   Data Scientist 2   \n",
       "44          44                                     Data Scientist   \n",
       "45          45                                                NaN   \n",
       "46          46                                                NaN   \n",
       "47          47                                                NaN   \n",
       "48          48                 Sr. Data Engineer / Data Scientist   \n",
       "49          49                                     Data Scientist   \n",
       "\n",
       "                                            company  \\\n",
       "0                                   Bank of America   \n",
       "1                                    Simple Finance   \n",
       "2                                            PayPal   \n",
       "3                               Shuchi Rana Sandbox   \n",
       "4                                            Google   \n",
       "5                         Appnomic Systems Pvt. Ltd   \n",
       "6                         Simplion Technologies Inc   \n",
       "7            Lawrence Livermore National Laboratory   \n",
       "8                   SPIN Analytics and Strategy LLC   \n",
       "9                                              Uber   \n",
       "10                               Ford Motor Company   \n",
       "11                                      HireStarter   \n",
       "12                                           Intuit   \n",
       "13                                    kWh Analytics   \n",
       "14                               Kohl's Corporation   \n",
       "15                                             EBay   \n",
       "16                   Data Management Services, Inc.   \n",
       "17                                  Tech Quarry LLC   \n",
       "18                                        OnboardIQ   \n",
       "19                                      Capital One   \n",
       "20                                          Agilent   \n",
       "21                                      AbilTo, Inc   \n",
       "22                           DoubleDown Interactive   \n",
       "23                            Sekisui XenoTech, LLC   \n",
       "24                                       eHire, LLC   \n",
       "25                         GoodDolphin Technologies   \n",
       "26                                            Zynga   \n",
       "27                                             Nike   \n",
       "28                                           Zillow   \n",
       "29                                        LumenData   \n",
       "30                                            Apple   \n",
       "31                                            Apple   \n",
       "32                                           Humana   \n",
       "33                                      HireStarter   \n",
       "34                                             Uber   \n",
       "35                                      AbilTo, Inc   \n",
       "36                                        Microsoft   \n",
       "37                                Caerus Associates   \n",
       "38                                        Supervalu   \n",
       "39                                              CGG   \n",
       "40                                   The World Bank   \n",
       "41                                       EventBoard   \n",
       "42                        Foundation Medicine, Inc.   \n",
       "43                                           Oracle   \n",
       "44                                       MD Insider   \n",
       "45                                      AbilTo, Inc   \n",
       "46                           DoubleDown Interactive   \n",
       "47                            Sekisui XenoTech, LLC   \n",
       "48  Nineteen Eleven Solutions(Implementing Partner)   \n",
       "49                                          ektello   \n",
       "\n",
       "                                             location           salary  \\\n",
       "0                                       Charlotte, NC              NaN   \n",
       "1                                        Portland, OR              NaN   \n",
       "2                                        San Jose, CA              NaN   \n",
       "3                                      Menlo Park, CA              NaN   \n",
       "4                                   Mountain View, CA              NaN   \n",
       "5                                       Sunnyvale, CA              NaN   \n",
       "6                                       Sunnyvale, CA              NaN   \n",
       "7                                 Livermore, CA 94550              NaN   \n",
       "8                                        San Jose, CA              NaN   \n",
       "9                                        New York, NY              NaN   \n",
       "10                                       Dearborn, MI              NaN   \n",
       "11                                         Austin, TX              NaN   \n",
       "12                            Mountain View, CA 94039              NaN   \n",
       "13  San Francisco, CA 94104 (Financial District area)  $120,000 a year   \n",
       "14                                 Milpitas, CA 95035              NaN   \n",
       "15                                       San Jose, CA              NaN   \n",
       "16                                Frederick, MD 21701              NaN   \n",
       "17                                    San Antonio, TX              NaN   \n",
       "18                                  San Francisco, CA              NaN   \n",
       "19                                       Richmond, VA              NaN   \n",
       "20                              Santa Clara, CA 95051              NaN   \n",
       "21                                       New York, NY              NaN   \n",
       "22                                        Seattle, WA              NaN   \n",
       "23                                    Kansas City, KS              NaN   \n",
       "24                  Atlanta, GA 30326 (Buckhead area)  $150,000 a year   \n",
       "25                                      Sunnyvale, CA              NaN   \n",
       "26                                  San Francisco, CA              NaN   \n",
       "27                                       Portland, OR              NaN   \n",
       "28                  Seattle, WA 98101 (Downtown area)              NaN   \n",
       "29                              Santa Clara, CA 95054              NaN   \n",
       "30                             Santa Clara Valley, CA              NaN   \n",
       "31                             Santa Clara Valley, CA              NaN   \n",
       "32                                         Irving, TX              NaN   \n",
       "33                                         Austin, TX              NaN   \n",
       "34                                       New York, NY              NaN   \n",
       "35                                       New York, NY              NaN   \n",
       "36                                      Sunnyvale, CA              NaN   \n",
       "37                                      Arlington, VA              NaN   \n",
       "38                                   Eden Prairie, MN              NaN   \n",
       "39                                      United States              NaN   \n",
       "40                                     Washington, DC              NaN   \n",
       "41                                 Salt Lake City, UT              NaN   \n",
       "42                                      Cambridge, MA              NaN   \n",
       "43                                     Broomfield, CO              NaN   \n",
       "44                             Santa Monica, CA 90405              NaN   \n",
       "45                                       New York, NY              NaN   \n",
       "46                                        Seattle, WA              NaN   \n",
       "47                                    Kansas City, KS              NaN   \n",
       "48                                        Phoenix, AZ              NaN   \n",
       "49                               Farmington Hills, MI              NaN   \n",
       "\n",
       "                                          description senior manager expert  \\\n",
       "0   As well as deployment of advanced techniques (...  False   False  False   \n",
       "1   Predictive analytics, experimental design, dat...  False   False  False   \n",
       "2   Collaborate with other research scientists and...  False   False  False   \n",
       "3   Experiment engineers will be expected to help ...  False   False  False   \n",
       "4   Lead analytics aspects of client engagements i...  False   False  False   \n",
       "5   Weâ€™re looking for a data scientist to help us ...  False   False  False   \n",
       "6   Experienced in developing machine learning mod...  False   False  False   \n",
       "7   Data intensive applications, text processing, ...  False   False  False   \n",
       "8   Communicate insights and recommend areas for f...  False   False  False   \n",
       "9   Technical understanding must go from the highe...  False   False  False   \n",
       "10  Business users, existing data sources, databas...  False   False  False   \n",
       "11  Programming and experience required in SQL, Or...  False   False  False   \n",
       "12  Deep mastery of machine learning - Candidate m...  False   False  False   \n",
       "13  A track record of spotting relevant trends in ...  False   False  False   \n",
       "14  Data scientists interpret and apply data in an...  False   False  False   \n",
       "15  We use state-of-the-art big data infrastructur...  False   False  False   \n",
       "16  Data Management Services, Inc., is currently s...  False   False  False   \n",
       "17  Financial Analyst / Data Scientist*. Experienc...   True   False  False   \n",
       "18  Come help us build a brand new data platform, ...  False   False  False   \n",
       "19  Assess data quality, prepare data for processi...  False   False  False   \n",
       "20  You will be responsible for end to end analyti...  False   False  False   \n",
       "21  With our Engagement team, you will build predi...  False   False  False   \n",
       "22  As a Senior Data Warehouse Engineer, you will ...  False   False  False   \n",
       "23  Serves as Lead Scientist or Study Director. Th...  False   False  False   \n",
       "24  Strong background in applying statistical mach...   True   False  False   \n",
       "25  Design, develop, and implement statistical and...  False   False  False   \n",
       "26  Probability, statistics, data mining, predicti...  False   False  False   \n",
       "27  Requires chemistry, mechanical, material scien...  False   False  False   \n",
       "28  In particular, this role will span the gamut, ...  False   False  False   \n",
       "29  Classifying streaming machine data to enable p...  False   False  False   \n",
       "30  Experience with machine learning or data minin...  False   False  False   \n",
       "31  We are a cross functional group of statisticia...  False   False  False   \n",
       "32  Big Data â€“ Machine Learning Expert / Principal...  False   False   True   \n",
       "33  Programming and experience required in SQL, Or...  False   False  False   \n",
       "34  Technical understanding must go from the highe...  False   False  False   \n",
       "35  With our Engagement team, you will build predi...  False   False  False   \n",
       "36  Bing is seeking experienced data scientists an...  False   False  False   \n",
       "37  Caerus is seeking an experienced data scientis...  False   False  False   \n",
       "38  Develops machine learning, data mining,. Visua...  False   False  False   \n",
       "39  Experience and/or education in at least one of...  False   False  False   \n",
       "40  DIME Analytics provides support to research te...  False   False  False   \n",
       "41  The RoleWeâ€™re growing fast and need a top notc...  False   False  False   \n",
       "42  The analytics scientist will be responsible fo...  False   False  False   \n",
       "43  1-2 years of data science or applied analytics...  False   False  False   \n",
       "44  R, Python, Java, SQL. Reporting to the Directo...  False   False  False   \n",
       "45  With our Engagement team, you will build predi...  False   False  False   \n",
       "46  As a Senior Data Warehouse Engineer, you will ...  False   False  False   \n",
       "47  Serves as Lead Scientist or Study Director. Th...  False   False  False   \n",
       "48  Data Scientist has 3 components. Development o...   True   False  False   \n",
       "49  Technical experience in Deep Learning (academi...  False   False  False   \n",
       "\n",
       "   machlearn bigdata  \n",
       "0       True   False  \n",
       "1       True   False  \n",
       "2      False   False  \n",
       "3      False   False  \n",
       "4      False   False  \n",
       "5      False   False  \n",
       "6       True   False  \n",
       "7       True   False  \n",
       "8      False   False  \n",
       "9      False   False  \n",
       "10     False   False  \n",
       "11     False   False  \n",
       "12      True   False  \n",
       "13     False   False  \n",
       "14     False   False  \n",
       "15      True    True  \n",
       "16     False   False  \n",
       "17     False    True  \n",
       "18     False   False  \n",
       "19     False   False  \n",
       "20     False   False  \n",
       "21     False   False  \n",
       "22     False   False  \n",
       "23     False   False  \n",
       "24      True   False  \n",
       "25      True   False  \n",
       "26     False   False  \n",
       "27     False   False  \n",
       "28      True   False  \n",
       "29      True   False  \n",
       "30      True   False  \n",
       "31     False   False  \n",
       "32      True    True  \n",
       "33     False   False  \n",
       "34     False   False  \n",
       "35     False   False  \n",
       "36     False   False  \n",
       "37     False   False  \n",
       "38      True   False  \n",
       "39      True    True  \n",
       "40     False   False  \n",
       "41     False   False  \n",
       "42     False   False  \n",
       "43     False   False  \n",
       "44     False   False  \n",
       "45     False   False  \n",
       "46     False   False  \n",
       "47     False   False  \n",
       "48      True   False  \n",
       "49      True   False  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variable for 'senior'\n",
    "-\n",
    "\n",
    "project4.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9c9274ef-c9f5-4d56-b286-ecc8709eff9f"
   },
   "source": [
    "#### Rebuild this model with scikit-learn.\n",
    "- You can either create the dummy features manually or use the `dmatrix` function from `patsy`\n",
    "- Remember to scale the feature variables as well!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b76f65cd-cd3a-4e91-af55-12880be7b057"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy, AUC, precision and recall of the model. \n",
    "- Discuss the differences and explain when you want a high-recall or a high-precision model in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "8c22664b-92e4-4fc2-b7ac-fbac865845d3"
   },
   "source": [
    "#### Compare L1 and L2 regularization for this logistic regression model. What effect does this have on the coefficients learned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "172fd952-5012-4630-81f4-1206da6eb820"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "56cc8854-d722-411d-a6c7-e86310710f67"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "fead9b5b-7316-405d-87fd-e144dff0cbeb"
   },
   "source": [
    "#### Continue to incorporate other text features from the title or summary that you believe will predict the salary and examine their coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "12d5edeb-a272-43a0-9977-d951f12fedfb"
   },
   "source": [
    "#### Take ~100 scraped entries with salaries. Convert them to use with your model and predict the salary - which entries have the highest predicted salaries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Bonus: Use Count Vectorizer from scikit-learn to create features from the text summaries. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate the logistic regression model using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "fec80936-37bc-4922-89bd-b5d615566c9c"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "d42b9fd8-39d5-416a-b40b-7410e6396c11"
   },
   "source": [
    "#### Re-test L1 and L2 regularization. You can use LogisticRegressionCV to find the optimal reguarlization parameters. \n",
    "- Re-test what text features are most valuable.  \n",
    "- How do L1 and L2 change the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "7570e237-c8cc-4e26-b569-7aee10627e79"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "e3a0c83d-e3b8-4bed-b864-7e795b34a3d4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
